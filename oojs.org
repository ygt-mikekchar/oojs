* Re-examining Object Oriented Programming with JavaScript

#+BEGIN_QUOTE
In this post I'll define a rudimentary object system written in
JavaScript.  Of course JavaScript already *has* a rudimentary object
system.  However, I think it suffers from a confusing
conglomeration of competing ideas.  I think many people will be
surprised at how elegantly JavaScript can define an object system with
no new syntax.  While defining the system I hope to provoke thoughts about
what it means to be "Object Oriented".
#+END_QUOTE
-------------

One day at work, we were discussing languages that we enjoyed working
with.  Some people expressed surprise that very near the top of my
preferences I listed JavaScript.  It's a language that many people
use, but often only when they have no other choice.  Similarly,
I frequently bump into blogs on the internet expressing a distaste
(verging on disgust, in some cases) for object oriented programming (OOP).

If you hang around in the programming industry long enough you may
notice a common occurrence.  Sometimes someone has a seed of an idea.
It is not fully formed yet, but it has a lot of promise.  They work on
the idea for a while and word spreads.  Eventually it becomes well
known, with many people experimenting with it.  Evolution of the idea follows
several paths, each proponent injecting their own ideas, both good and
bad until the most widespread versions of the idea no longer closely
match the original.  Often the idea is derided as horrible, using
evidence gathered from popular views that no longer match the
original.

In that vein, you may be familiar with definitions of object oriented
programming (OOP) that involve things like "inheritance",
"polymorphism", "encapsulation", etc, etc.  However, in my own career
dominated mostly by object oriented programming, I have found that
these definitions fall short.  Indeed, all of those things are present
in object oriented systems, but they aren't the benefits that I
actually want from OOP.  Ideally, I'm just after better cohesion with
less unnecessary coupling in my code.  As a part of this, I value
being able to write generic code when it improves cohesion.

OOP evolved from several different backgrounds, which is, I think, one
of the reasons why our view is so muddled now. We have conflated a
bunch of competing ideas, not all of which are compatible with one
another.  For the purposes of this post I'm going to fall back on a
[[http://www.purl.org/stefan_ram/pub/doc_kay_oop_en][very simple
description of OO]] from Alan Kay, one of the original progenitors of
OOP:

#+BEGIN_QUOTE
OOP to me means only messaging, local retention and protection and
hiding of state-process, and extreme late-binding of all things. It
can be done in Smalltalk and in LISP. There are possibly other
systems in which this is possible, but I'm not aware of them. -- Alan Kay
#+END_QUOTE

He wrote that email in 2003 and I wonder if he dismissed JavaScript
out of hand.  I know at that time, I would have done the same.  Now I
wonder if we can't build something that comes close to matching his
view using only very basic JavaScript.

In this post I'll define a rudimentary object system written in
JavaScript.  Of course JavaScript already *has* a rudimentary object
system.  However, I think it suffers from the aforementioned confusing
conglomeration of competing ideas.  I think many people will be
surprised at how elegantly JavaScript can define an object system with
no new syntax.

I should point out that I am not suggesting that one actually *use*
this system.  It is just an exploration of ideas.  Similarly I am not
attempting to sway the reader into accepting JavaScript or even OOP as
a tool that they should use.  I am simply hoping to view the problem
from a different perspective.  If it proves interesting, then I will
be more than satisfied.

We're only going to use a few basic features of JavaScript in this
endeavour.  I'll use ES6 notation, because I find it more convenient,
but the vast majority of what I'm doing can be done just as easily (if
considerably more verbosely) in earlier versions of the language.
I'll point out any potential differences along the way. Even if you
have not used JavaScript extensively before, we are using so few
facilities of what makes up modern JavaScript, I think it will be
fairly easy to understand.

** Immutability and Idempotence

It may be surprising to start by looking at immutability.  There are a
couple of reasons why I feel it is necessary to do so.  Many
criticisms of OOP come from programmers who have experience with pure
functional languages.  For some reason, they believe that mutability
is inherent to OOP.  I want to dispell that notion.  It is just as
easy to write an object system using immutable data structures and
pure functions as it is to write one with mutable data structures.

Having just made that comment, I have to admit that the vast majority
of OO programming languages make it very difficult to write immutable
code.  The issues that you have to keep in mind are not obvious.  For
that reason, many (most?) object oriented programmers do not
understand the cost of mutability in their code.  As we'll see, it's
not always easy to contain that mutability, which leads to code that
is more difficult to reason about than necessary.

Finally, JavaScript has made a few language design choices that impact
how we can write immutable code.  I think it is worth going over these
as some of them may be surprising unless you understand JavaScript
very well.  This section will also serve as an introduction to all of
the JavaScript facilities we will use to build the object system.

*** References and Values

JavaScript is a garbage collected language.  What that means is that
the programmer does not explicitly allocate memory.  A separate
facility in the run-time system occasionally looks for data that is no
longer being used and frees the memory.  All variables in JavaScript are
references that point to values (usually allocated on the heap).

Early versions of JavaScript had only mutable variables.  That is, you
can change the value that they point to.  ~var~ declares a mutable
variable with function scope (it can be used anywhere inside the
enclosing function).  While the variable is mutable, the value that it
references is often immutable (it can't be modified).  Here is an
example:

#+BEGIN_SRC js
  var a = 5;
  var b = a;
  a += 5;

  return {a, b};
#+END_SRC

#+RESULTS:
: { a: 10, b: 5 }

#+BEGIN_SRC js
> { a: 10, b: 5 }
#+END_SRC

Another way to think about this is that we can point our variable (via
assignment) to any value we want, but the value itself can not
change.  The value ~5~ does not suddenly become ~6~, but our variable can
point to ~5~ or ~6~ (or any other value).  In this way, the variable is
mutable (can be changed) while the value is immutable (can not be
changed).  You may be forgiven for thinking this is obvious -- where
would we be if ~5~ suddenly became ~6~?  However, some kinds of
values *can* be changed (which we will see later).

ES6 introduced 2 other kinds of variables: ~let~ and ~const~.  ~let~
variables are mutable, but block scoped. ~const~ variables are
immutable while also being block scoped.  "Block scoped" means that
you can use the variable anywhere within the block in which it is
declared, but not outside.  Blocks are generally defined with ~{}~
characters.  An example might be an ~if~ statement.  With ~const~
variables, you can not change the reference after they have been
assigned once.  If you only use ~const~ variables that point to
immutable values, then you can be sure that everything is immutable.

Most values in JavaScript are immutable.  Surprisingly, even string
values are immutable in JavaScript (although, unfortunately it doesn't
throw an error if you try to mutate them).  For example:

#+BEGIN_SRC js
  var a = "bar";
  a[2] = 'z';

  return {a};
#+END_SRC

#+RESULTS:
: { a: 'bar' }

#+BEGIN_SRC js
> { a: 'bar' }
#+END_SRC

Even constructed strings are immutable.  For example adding two
strings together returns an immutable string.  This surprised me
slightly when I looked into it, but there are some performance reasons
why immutable strings are beneficial.

There are only a few value types that are mutable in JavaScript.  Anyone
who has worked with immutable data structures before knows that they
can be tricky to work with.  For performance reasons, it's often
helpful to have mutable arrays, and JavaScript's arrays are mutable.

#+BEGIN_SRC js
  var a = [1, 2, 3];
  var b = a;

  a[2] = 4;

  return {a, b};
#+END_SRC

#+RESULTS:
: { a: [ 1, 2, 4 ], b: [ 1, 2, 4 ] }

#+BEGIN_SRC js
> { a: [ 1, 2, 4 ], b: [ 1, 2, 4 ] }
#+END_SRC

The other main type of value that is mutable in JavaScript is the
"object".  An "object" is not as special as you might imagine from its
name.  In other languages it would be called a "dictionary", "hash",
"record" or "struct".  The name is quite unfortunate because it
conflates the OO notion of "object" with something that can be used to
construct an object.  To avoid that confusion, I'm going to call it a
"dictionary" in this post, which is what Smalltalk calls it.  After
all, JavaScript was originally intended to be similar to Smalltalk, so
I think it's appropriate.  I apologise in advance if you find it
confusing.

Here is an example of the mutability of dictionaries:

#+BEGIN_SRC js
  const a = {foo: 1};
  const b = a;
  a.foo = 2;

  return {a, b};
#+END_SRC

#+RESULTS:
: { a: { foo: 2 }, b: { foo: 2 } }

#+BEGIN_SRC js
> { a: { foo: 2 }, b: { foo: 2 } }
#+END_SRC

It is important to understand that even though the *variables* ~a~ and
~b~ are immutable (const), the *values* that they point to are not.
Personally, I find the keywords pretty confusing, but as long are you
keep in mind that they refer to the *variable* you'll be fine.  It's
also important to realise that *assignment* points a variable to a
*new value*.  For example:

#+BEGIN_SRC js
  let a = {foo: 1};
  let b = a;
  a = {foo: 2};

  return {a, b};
#+END_SRC

#+RESULTS:
: { a: { foo: 2 }, b: { foo: 1 } }

#+BEGIN_SRC js
> { a: { foo: 2 }, b: { foo: 1 } }
#+END_SRC

*** Functions, Closures and Currying

In JavaScript, functions are "first class citizens".  In other words
a function is a value just like any other value.  Once a function has
been defined, you can't really modify it.  Just in the same way that
the value ~5~ can't suddenly become ~6~, one function can't suddenly
transform into a different function.

Here is an example:

#+BEGIN_SRC js
  let a = function add(x, y) { return x + y };
  let b = a;
  let result_a1 = a(1, 2);
  a = function subtract(x, y) { return x - y };
  let result_a2 = a(1, 2);
  let result_b = b(1, 2);

  return {a, b, result_a1, result_a2, result_b};
#+END_SRC

#+RESULTS:
: { a: [Function: subtract],
:   b: [Function: add],
:   result_a1: 3,
:   result_a2: -1,
:   result_b: 3 }

#+BEGIN_SRC js
> { a: [Function: subtract],
    b: [Function: add],
    result_a1: 3,
    result_a2: -1,
    result_b: 3 }
#+END_SRC

While admirably clear, this syntax is pretty awkward for using
functions in any more than a rudimentary way.  ES6 introduced a
notation for lambdas (unnamed functions) which is more convenient.  I
will be using it for the remainder of this post.  Of course the
downside is that lambdas have no name.  Here is the same code using
that notation:

#+BEGIN_SRC js
  let a = (x, y) => x + y;
  let b = a;
  let result_a1 = a(1, 2);
  a = (x, y) => x - y;
  let result_a2 = a(1, 2);
  let result_b = b(1, 2);

  return {a, b, result_a1, result_a2, result_b};
#+END_SRC

#+RESULTS:
: { a: [Function: a],
:   b: [Function: a],
:   result_a1: 3,
:   result_a2: -1,
:   result_b: 3 }

#+BEGIN_SRC js
> { a: [Function: a],
    b: [Function: a],
    result_a1: 3,
    result_a2: -1,
    result_b: 3 }
#+END_SRC

Note: The "double arrow" notation is not strictly equivalent to
~function~, since it handles ~this~ differently.  In this post, I
won't be using ~this~ so I will treat them as the same.

Not only can functions be assigned to variables, they can also be
passed to and returned from functions.  This leads us to another
feature, which is common in many popular languages today: closures.
While common today, when it was first introduced it was a pretty
esoteric feature that was absent in most mainstream programming
languages. An example is probably the easiest way to describe a closure.

#+BEGIN_SRC js
  const add = (x) => {
    return (y) => x + y;
  };
  const inc = add(1);
  const add_two = add(2);

  return {inc_5: inc(5), add_two_6: add_two(6), inc_3: inc(3)};
#+END_SRC

#+RESULTS:
: { inc_5: 6, add_two_6: 8, inc_3: 4 }

#+BEGIN_SRC js
> { inc_5: 6, add_two_6: 8, inc_3: 4 }
#+END_SRC

What is happening here?  The function ~add~ takes a single parameter,
~x~, and returns a new function that takes a single parameter y.  The
function it returns adds ~x~ and ~y~ together.  The function returned
by ~add~ needs to remember ~x~, even though ~x~ is no longer in scope.
We say that the function returned by ~add~ "closes over ~x~".  That
function is known as a "closure".

It is important to understand that a closure remembers the value of
the variable *when it was constructed*, not when it was called.  So in
this case, ~inc~ always uses the value of ~1~ for ~x~, while ~add_two~
always uses the value of ~2~ for ~x~.  As long as the value is immutable,
it can not change.  However, you must beware if you close over a
dictionary (aka object) or array because they are *not*
immutable. Because this has serious consequences, we'll explore this
in more detail shortly.

In functional programming, this kind of construction is very popular.
Earlier we saw a definition of ~add~ that took 2 parameters (~x~ and
~y~).  Just to remind you:

#+BEGIN_SRC js
  const add = (x, y) => x + y;
#+END_SRC

We also had a version that returned a closure for dealing with the
second paramer, ~y~:
#+BEGIN_SRC js
  const add = (x) => {
    return (y) => x + y;
  };
#+END_SRC

ES6 allows you to omit the parentheses in the parameter list
if there is exactly one parameter.  You can also omit the braces and
~return~ statement in the body if it is composed of exactly one
expression.  With that we can refactor the second version
into something that more closely resembles what you would find in a
functional programming language:

#+BEGIN_SRC js
  const add = x => y =>
    x + y;
#+END_SRC

Before ES6 you would have to write this as:

#+BEGIN_SRC js
  var add = function(x) {
    return function(y) {
      return x + y;
    };
  };
#+END_SRC

The older form is easier to understand what is happening under
the hood, but the first is dramatically easier to type and to reason
about, once you understand it.  For this reason, I will stick to the
newer, compressed ES6 style as much as possible.

Syntax aside, this is an example of "currying".  Every function that
can take 2 parameters can be converted into a function that takes 1
parameter and returns a closure that takes 1 parameter.  You can
extend that to functions with any number of parameters, but I will
leave that as an exercise for the reader.

The functions we defined earlier, ~inc~ and ~add_two~, are examples of
"partially applied functions".  "Partially applied" means that only
some of the parameters have been specified.  The result is a function that
allows you to specify the remaining parameters.  Just to remind you,
here's the definition of ~inc~ again:

#+BEGIN_SRC js
  const inc = add(1);
#+END_SRC

You'll notice that while ~inc~ is a function, we don't specify the
parameter in its definition.  This is called "point free form" in
functional programming languages.  While it takes some getting used
to, it can sometimes make the intent more clear: ~inc~ is equivalent to
adding one to something.

Note that we can specify all of the parameters to ~add~ if we want to,
although the syntax is slightly unfortunate in JavaScript (probably a
result of early demands to make it look like Java, even though it
operates differently under the hood):

#+BEGIN_SRC js
  const add = x => y =>
    x + y;
  const a = add(1)(3);

  return {a};
#+END_SRC

#+RESULTS:
: { a: 4 }

#+BEGIN_SRC js
> { a: 4 }
#+END_SRC

*** Idempotence

Earlier I mentioned that as long as the variables closed over in a
closure are immutable, they can't change value.  It is important to
understand, though, that function parameters are mutable in
JavaScript:

#+BEGIN_SRC js
  const foo = (x) => {
    x = x + 1;
    return x;
  };

  return {foo_4: foo(4)};
#+END_SRC

#+RESULTS:
: { foo_4: 5 }

#+BEGIN_SRC js
> { foo_4: 5 }
#+END_SRC

Effectively, this makes closures mutable.  Consider the following:

#+BEGIN_SRC js
  const init = x => y => {
    x = x + y;
    return x;
  };
  const advance = init(0);

  return {
    a: advance(1),
    b: advance(1),
    c: advance(1),
    d: advance(1)
  };
#+END_SRC

#+RESULTS:
: { a: 1, b: 2, c: 3, d: 4 }

#+BEGIN_SRC js
> { a: 1, b: 2, c: 3, d: 4 }
#+END_SRC

Every time you call ~advance~ it increments ~x~ the appropriate
amount.  This value is stored as state in the closure.  While you
can't change the function after it has been defined, its operation
*can* change because the variables that are closed over are mutable.

A function that always returns the same value when given the same
parameters is called *idempotent*.  Idempotent functions are *much*
easier to reason about because we don't have consider any previous
state.  Especially when debugging a problem, you don't always know
what state caused a problem, so whenever possible we want to write
idempotent functions.

We have to be especially careful when we close over mutable values.
Even if you don't reassign the closed over variable, the closure can be
mutated simply by mutating the value.  Here is an example:

#+BEGIN_SRC js
  const init = x => y =>
    x.count + y;
  const dict = {count: 0};
  const add_to_count = init(dict);

  const a = add_to_count(1);
  const b = add_to_count(1);
  dict.count = 5;
  const c = add_to_count(1);

  return {a, b, c};
#+END_SRC

#+RESULTS:
: { a: 1, b: 1, c: 6 }

#+BEGIN_SRC js
> { a: 1, b: 1, c: 6 }
#+END_SRC

Even though we never reassigned the variable ~x~, the closure is not
idempotent simply because ~x~ was mutable.  This is an important
lesson: mutability is a bit like a disease.  One piece of mutable
data can spread the mutability to other data structures if you do not
take care to isolate it.  This is not a problem with OOP, it is just
the nature of programming.

** Building a Rudimentary Object System

With just these facilities, we can now build a rudimentary object
system. The astute reader will notice by now that I have not really
discussed OO at all up until this point.  In fact, everything I've
talked about is really the basics of *functional* programming.  I hope
you can see that, if you are careful, JavaScript could make a pretty
good functional language.  How does that relate to the object oriented
paradigm?

*** Defining a Rectangle

First, I have to admit that this example is highly contrived.  One of
the worst problems of explanations of OOP is the use of toy problems
where real world issues rarely rear their ugly heads.  However, as I
stated in the introduction, my goal here is not to explain, or sell
you on OOP.  I merely want to look at the issue from a different angle
and hopefully start a thought process for carrying it on further.

With that disclaimer, let's start in a kind of unorthodoxed way.  I
think most people would start their object oriented modelling by
defining what a rectangle looks like: i.e. what a struct or dictionary
of it would look like.  However, Alan Kay doesn't talk at all about
the structure of objects in his very concise definition.  He talks
about messaging, dealing with state, and late binding.  Let's start
with a function.

#+BEGIN_SRC js
  const area = (length, width) =>
    length * width;

  return {area_5_2: area(5, 2)};
#+END_SRC

#+RESULTS:
: { area_5_2: 10 }

#+BEGIN_SRC js
> { area_5_2: 10 }
#+END_SRC

This is not very exciting as it stands, but it gives us some insight
about rectangles: they have a length and a width.  Let's write another
function that explores other properties of rectangles.

#+BEGIN_SRC js
  const translate = (x, y, dx, dy) =>
    ({ x: x + dx, y: y + dy });

  return {translate_1_2_4_5: translate(1, 2, 4, 5)};
#+END_SRC

#+RESULTS:
: { translate_1_2_4_5: { x: 5, y: 7 } }

#+BEGIN_SRC js
> { translate_1_2_4_5: { x: 5, y: 7 } }
#+END_SRC

In this case, "translate" moves the rectangle to some other point on
the plane.  We have the "x" and "y" coordinates for the position of
the rectangle, and the amount we want to move in both the x and y
directions. It returns the position where we will move to.  In this
case, I'm returning a dictionary.  However, I'm not very happy with
this implementation.  The most glaring problem is that the position
I'm passing in (two numbers: "x" and "y") is not the same type as the
position I'm returning (a dictionary containing "x" and "y").

The other thing I notice upon reflecting on this code is that
"translate" is not strictly a behaviour of a rectangle.  It's a
behaviour of the point that represents the rectangle's position.
Let's back up and define that point before we go any further.

*** Create a Point "class"

The most obvious way to proceed is to represent a point as a
dictionary, exactly the way we did when we returned the translated
position.  However, looking at Alan Kay's description of OOP, I'm not
convinced that this will bring us closer to his vision.  Is there a
different way of representing the object?  One of the clues might come
from the phrase "local retention ... of state-process".  We have
already seen a way to do that: closures.  Consider the following:

#+BEGIN_SRC js
  const Point = (x, y) => (
    {
      translate: (dx, dy) =>
        Point(x + dx, y + dy)
    }
  );

  const point = Point(1, 2);

  return {translate_4_5: point.translate(4, 5)};
#+END_SRC

#+RESULTS:
: { translate_4_5: { translate: [Function: translate] } }

#+BEGIN_SRC js
> { translate_4_5: { translate: [Function: translate] } }
#+END_SRC

Let's just walk through this.  "Point" is a function that takes "x"
and "y" coordinates.  It returns a dictionary that contains a single
entry: "translate".  Translate contains a function that runs the
"Point" function, with updated coordinates.  If you are familiar with
OOP languages, you might recognise "Point" as being a constructor.

What's unusual is that we *don't seem to store the attributes of Point
anywhere!*  In reality, they *are* stored, but in the closure,
"translate".  The really interesting thing is that there is literally
no way for us to access the values stored in our Point object.  Even
when we dump the object, we just see that we have a dictionary
containing a function.  Let's amend this slightly.

I'll want to reuse this definition in the future, so I'm going to
store it to a file called ~point1.js~.  I'll use Node's module system
to export and then reimport the "class" we've made.

#+BEGIN_SRC js :tangle point1.js
  const Point = (x, y) => (
    {
      show: () =>
        ({x, y}),
      translate: (dx, dy) =>
        Point(x + dx, y + dy)
    }
  );

  module.exports = Point;
#+END_SRC

#+BEGIN_SRC js
  const Point = require("point1.js");

  const point = Point(1, 2);

  const orig = point.show();
  const translated = point.translate(4, 5).show();

  return {orig, translated};
#+END_SRC

#+RESULTS:
: { orig: { x: 1, y: 2 }, translated: { x: 5, y: 7 } }

#+BEGIN_SRC js
> { orig: { x: 1, y: 2 }, translated: { x: 5, y: 7 } }
#+END_SRC

Now we've added an accessor that let's us inspect the private
attributes.  The interesting thing here is that our Point object (at
least from the perspective of the attributes) is *still* immutable.
We can't change it.  For example:

#+BEGIN_SRC js
  const Point = require("point1.js");

  const point = Point(1, 2);
  point.show().x = 42;

  return {point: point.show()};
#+END_SRC

#+RESULTS:
: { point: { x: 1, y: 2 } }

#+BEGIN_SRC js
> { point: { x: 1, y: 2 } }
#+END_SRC

"show" returns a *copy* of the attributes, so there is still no way
for us to mutate the object.  In this way, I think we're a lot closer
to Alan Kay's description: "local retention and protection and
hiding of state-process".  Our state is hidden by default.  Even if we
show the values with an accessor, the state is still immutable.  Of
particular interest to me is that as long as we restrict ourselves to
a very basic subset of JavaScript, the code is also extremely easy to
write and read (apart from the ugly way one must return dictionaries).
It also requires no new syntax for the language.

Warning: if ~show~ makes you feel uncomfortable, then I think you have
good instincts.  We will discuss this more fully later.

It interesting to consider that our Point "class" is just a function.
There is no particular reason to create new syntax around something so
simple.  Just as in FP, the state in the system is simply the
application of parameters to a function.  An object system can be
implemented in exactly the same way.

Another interesting thing is that our "object" is just a dictionary of
closures -- in essence a dictionary of partially applied functions.
As you will see, we can use this fact to implement subtype
polymorphism extremely simply. The question we have to consider is
whether or not these closures resemble the "messages" in Alan Kay's
vision.

*** How to Make a Mutable Object

What if we wanted a mutable Point object?  Remember that parameters
passed to a function are mutable.  This means that we can mutate
~x~ and ~y~ in our closures returned by ~Point~.  I'll save this
as ~mutable_point.js~.

#+BEGIN_SRC js :tangle mutable_point.js
  const Point = (x, y) => {
    const self = {
      show: () =>
        ({x, y}),
      setX: (new_x) =>
        x = new_x,
      setY: (new_y) =>
        y = new_y,
      translate: (dx, dy) => {
        self.setX(x + dx);
        self.setY(y + dy);
      }
    };
    return self;
  };

  module.exports = Point;
#+END_SRC

Notice that we've added a couple of other facilities here.  Since the
~Point~ is mutable, we might as well translate it by mutating ~x~ and
~y~.  This requires us to have access to our own object, which is
easily done by assigning a variable called ~self~.

Does it work?

#+BEGIN_SRC js
  const Point = require("mutable_point.js");

  const point = Point(1, 2);
  const orig = point.show();

  point.setX(23);
  point.setY(42);
  const modified = point.show();

  point.translate(10, 20);
  const translated = point.show();

  return {orig, modified, translated};
#+END_SRC

#+RESULTS:
: { orig: { x: 1, y: 2 },
:   modified: { x: 23, y: 42 },
:   translated: { x: 33, y: 62 } }

#+BEGIN_SRC js
> { orig:       { x:  1, y:  2 },
    modified:   { x: 23, y: 42 },
    translated: { x: 33, y: 62 } }
#+END_SRC

Of course just being able to do something doesn't necessarily mean
that you *should* do that thing.  Should we make ~Point~ mutable?
Generally speaking, you should not make something mutable unless you
really have to. Immutable functions make reasoning about the code much
easier.  However, in the next section you will see some examples of
why we tend to get tempted into using mutable functions.

*** Four Sided Shapes

Let's go back to the rectangle and see what it looks like if we use an
immutable ~Point~ class.

#+BEGIN_SRC js :tangle rect1.js
  const Rect = (pos, length, height) => {
    return {
      show: () => {
        return {pos: pos.show(), length: length, height: height};
      },
      area: () =>
        length * height,
      translate: (dx, dy) =>
        Rect(pos.translate(dx, dy), length, height)
    };
  };

  module.exports = Rect;
#+END_SRC

#+BEGIN_SRC js
  const Point = require("point1.js");
  const Rect = require("rect1.js");

  const point = Point(1, 2);
  const rect = Rect(point, 4, 5);

  const orig = rect.show();
  const translated = rect.translate(10,20).show();
  const area = rect.area();

  return {orig, translated, area};
#+END_SRC

#+RESULTS:
: { orig: { pos: { x: 1, y: 2 }, length: 4, height: 5 },
:   translated: { pos: { x: 11, y: 22 }, length: 4, height: 5 },
:   area: 20 }

#+BEGIN_SRC js
> { orig:       { pos: { x:  1, y:  2 }, length: 4, height: 5 },
    translated: { pos: { x: 11, y: 22 }, length: 4, height: 5 },
    area: 20 }
#+END_SRC

Let's explore what a mutable ~Rect~ would look like:

#+BEGIN_SRC js :tangle mutable_rect.js
  const Rect = (pos, length, height) => {
    return {
      show: () => {
        return {pos: pos.show(), length: length, height: height};
      },
      area: () =>
        length * height,
      translate: (dx, dy) =>
        pos.translate(dx, dy)
    };
  };

  module.exports = Rect;
#+END_SRC

#+BEGIN_SRC js
  const Point = require("mutable_point.js");
  const Rect = require("mutable_rect.js");

  const point = Point(1, 2);
  const rect = Rect(Point(1, 2), 4, 5);

  const orig = rect.show();
  rect.translate(10, 20);
  const translated = rect.show();
  const area = rect.area();

  return {orig, translated, area};
#+END_SRC

#+RESULTS:
: { orig: { pos: { x: 1, y: 2 }, length: 4, height: 5 },
:   translated: { pos: { x: 11, y: 22 }, length: 4, height: 5 },
:   area: 20 }

#+BEGIN_SRC js
> { orig:       { pos: { x:  1, y:  2 }, length: 4, height: 5 },
    translated: { pos: { x: 11, y: 22 }, length: 4, height: 5 },
    area: 20 }
#+END_SRC

It seems to work almost identically, so you might be forgiven for
wondering what the big deal is.  Why do I maintain that immutability
leads to easier to reason code?  Consider this scenario:

#+BEGIN_SRC js
  const Point = require("mutable_point.js");
  const Rect = require("mutable_rect.js");

  const point = Point(1, 2);
  const rect1 = Rect(point, 4, 5);
  const rect2 = Rect(point, 10, 20);

  const orig1 = rect1.show();
  const orig2 = rect2.show();
  rect1.translate(10, 20);
  const final1 = rect1.show();
  const final2 = rect2.show();

  return {orig1, orig2, final1, final2};
#+END_SRC

#+RESULTS:
: { orig1: { pos: { x: 1, y: 2 }, length: 4, height: 5 },
:   orig2: { pos: { x: 1, y: 2 }, length: 10, height: 20 },
:   final1: { pos: { x: 11, y: 22 }, length: 4, height: 5 },
:   final2: { pos: { x: 11, y: 22 }, length: 10, height: 20 } }

#+BEGIN_SRC js
> { orig1:  { pos: { x:  1, y:  2 }, length:  4, height:  5 },
    orig2:  { pos: { x:  1, y:  2 }, length: 10, height: 20 },
    final1: { pos: { x: 11, y: 22 }, length:  4, height:  5 },
    final2: { pos: { x: 11, y: 22 }, length: 10, height: 20 } }
#+END_SRC

You can see that even though we only translated ~rect1~, ~rect2~
ended up moving as well because they shared the same ~point~.  Let's
try the same thing with immutable ~Rects~.

#+BEGIN_SRC js
  const Point = require("point1.js");
  const Rect = require("rect1.js");

  const point = Point(1, 2);
  const rect1 = Rect(point, 4, 5);
  const rect2 = Rect(point, 10, 20);

  const orig1 = rect1.show();
  const orig2 = rect2.show();
  const final1 = rect1.translate(10, 20).show();
  const final2 = rect2.show();

  return {orig1, orig2, final1, final2};
#+END_SRC

#+RESULTS:
: { orig1: { pos: { x: 1, y: 2 }, length: 4, height: 5 },
:   orig2: { pos: { x: 1, y: 2 }, length: 10, height: 20 },
:   final1: { pos: { x: 11, y: 22 }, length: 4, height: 5 },
:   final2: { pos: { x: 1, y: 2 }, length: 10, height: 20 } }

#+BEGIN_SRC js
> { orig1:  { pos: { x:  1, y:  2 }, length:  4, height:  5 },
    orig2:  { pos: { x:  1, y:  2 }, length: 10, height: 20 },
    final1: { pos: { x: 11, y: 22 }, length:  4, height:  5 },
    final2: { pos: { x:  1, y:  2 }, length: 10, height: 20 } }
#+END_SRC

In this way you can see that the immutable version is less prone to
strange bugs.  Of course in a simple example it's easy to remember
that the point is contained in *both* rectangles.  In a large system,
though, requiring the programmer to remember the state of all the
objects verges on impossibility.  We are forced to run a debugger and
inspect the state in the running code.  With the immutable version we
can reason about the state of the system simply by reading the source
code.  It's a clear win for immutability, which is why I suggest using
it as much as you can.

*** Immutability Comes with a Cost

It's incredibly easy to say, "Mutability is bad.  Let's just avoid
it".  Most programmers I know already realise that mutability causes
problems.  Why do they continue to write code with mutable state?
To investigate that I will introduce an inheritence hierarchy a little
bit.  We're going to make a square.

A square is just a rectangle with the height the same as the length.

#+BEGIN_SRC js :tangle square1.js
  const Rect = require("rect1.js");

  const Square = (pos, length) => {
    const rect = Rect(pos, length, length);
    return {
       ...rect,
      show: () =>
        ({pos: pos.show(), length}),
      translate: (dx, dy) =>
        Square(pos.translate(dx, dy), length)
    };
  };

  module.exports = Square;
#+END_SRC

You notice that the ~area~ method does not appear in this class.
That's because we are "inheriting" it from our ~rect~ object.

We're doing something a little bit tricky with the ES6 spread operator
here.  Essentially, what it does is create a new dictionary, merging
our new functions with the functions of the parent class.  The nice
thing about this approach is that it does not mutate the parent:

#+BEGIN_SRC js
  const parent = { foo: () => "bar" };
  const child = { ...parent, foo: () => "baz" };

  return { parent_foo: parent.foo(), child_foo: child.foo() };
#+END_SRC

#+RESULTS:
: { parent_foo: 'bar', child_foo: 'baz' }

#+BEGIN_SRC js
> { parent_foo: 'bar', child_foo: 'baz' }
#+END_SRC

In earlier version of JavaScript, you would have to write a function
to do the same thing, so this is really a massive win for ES6.

Let's see how the ~Square~ class works:

#+BEGIN_SRC js
  const Point = require("point1.js");
  const Square = require("square1.js");

  const point = Point(1, 2);
  const square = Square(point, 4);

  const orig = square.show();
  const translated = square.translate(10, 20).show();
  const area = square.area();

  return {orig, translated, area};
#+END_SRC

#+RESULTS:
: { orig: { pos: { x: 1, y: 2 }, length: 4 },
:   translated: { pos: { x: 11, y: 22 }, length: 4 },
:   area: 16 }

#+BEGIN_SRC js
> { orig:       { pos: { x:  1, y:  2 }, length: 4 },
    translated: { pos: { x: 11, y: 22 }, length: 4 },
    area: 16 }
#+END_SRC

It works pretty well and apart from potentially violating the Liskov
Substitution Principle, which we will talk about later, there doesn't
immediately seem to be any problem.  I don't like repetition, though.
There is one line that bothers me:

#+BEGIN_SRC js
      translate: (dx, dy) =>
        Square(pos.translate(dx, dy), length)
#+END_SRC

Compare that to the version in ~Rect~:

#+BEGIN_SRC js
      translate: (dx, dy) =>
        Rect(pos.translate(dx, dy), length)
#+END_SRC

It is virtually the same.  In this case the code is pretty trivial, so
I don't really mind typing it again, but you can imagine cases where
it might be very difficult.  The only difference is in the type of the
value that is returned from the function. What this means is that the
translate method in ~Square~ is not the same function as the translate
method in ~Rect~.  I'm sure that will be a surprising statement for
many, so to explain it, let's implement a mutable version of ~Square~.

#+BEGIN_SRC js :tangle mutable_square.js
  const Rect = require("mutable_rect.js");

  const Square = (pos, length) => {
    const rect = Rect(pos, length, length);
    return {
       ...rect,
      show: () =>
        ({pos: pos.show(), length})
    };
  };

  module.exports = Square;
#+END_SRC

#+BEGIN_SRC js
  const Point = require("mutable_point.js");
  const Square = require("mutable_square.js");

  const point = Point(1, 2);
  const square = Square(point, 4);

  const orig = square.show();
  square.translate(10, 20);
  const translated = square.show();
  const area = square.area();

  return {orig, translated, area};
#+END_SRC

#+RESULTS:
: { orig: { pos: { x: 1, y: 2 }, length: 4 },
:   translated: { pos: { x: 11, y: 22 }, length: 4 },
:   area: 16 }

#+BEGIN_SRC js
> { orig:       { pos: { x:  1, y:  2 }, length: 4 },
    translated: { pos: { x: 11, y: 22 }, length: 4 },
    area: 16 }
#+END_SRC

You will notice that in our mutable version, we don't have to rewrite
~translate~.  The functionality for ~Square~ is exactly the same as
for ~Rect~ so we can just inherit it.  However, it goes a bit further
than that.  In our immutable version, the functionality is almost the
same.  The only difference is the return type.  The ~Rect~ version
returns a ~Rect~ and the ~Square~ version returns a ~Square~.  In the
mutable version, we always return ~null~.

Even if we decided to make a new implementation of ~translate~ in the
mutable version for some reason, we would still return ~null~.  This
means that whenever we have a ~Square~ it works exactly the same as a
~Rectangle~.  We can substitute a ~Rectangle~ with a ~Square~ in our
code and it will work *exactly* the same.

With the immutable version, this is not true.  ~translate~ returns
different types of objects.  At the moment, both ~Square~ and
~Rectangle~ are roughly equivalent, so you can get away with it, but
as we will see soon, it can become much trickier.

Earlier I mentioned the Liskov Substitution Principle.  A simple
statement of this principle (which I lifted from Wikipedia) is
that if S is a subtype of T, then objects of type T in a
program may be replaced with objects of type S without altering any of
the desirable properties of that program.

*** Covariance and Contravariance

I always find the Liskov Substitution Principle, as stated previously,
to be a bit vague.  What does "altering any of the desirable properties"
really mean? Another way to state it is that inherited methods must
have the following properties:

  - The return types for the functions must be covariant
  - The arguments for the functions must be contravariant

There are a lot of technical ways to describe covariance and
contravariance, but for the purposes of this post I'll discuss a more
intuitive way to look at it.  While I discuss this, it is important to
keep in mind that the co/contra-variance goes in the direction of
the *child class* to the *base class*.  Personally, I find that
a bit confusing, but that's how it is described in the literature.

**** Covariance

Imagine you have an array that contains numbers.  You want to convert
that array to one that contains letters (perhaps 1 becomes "a",
2 becomes "b", etc).  We can easily write a function that maps
integers to letters using that rule.  Once we have such a function,
you can imagine that it is trivial to take all of the integers out of
the array, convert them to letters, and then put the result back into
an array.  Indeed, in JavaScript we would likely use the ~map~
function on ~Array~ to do such a thing (in other languages the
function is sometimes called ~fmap~).

If you can do such a thing, you have a "covariant" relationship.  In
other words, an array of numbers is covariant with an array of
letters.  Earlier we said that the return types of inherited functions
must be covariant.  Let's explain that a bit.

Imagine that an object is just a container for data.  It's easy to
imagine because that's usually how we think of objects.  A ~Rect~
object contains some data (a ~Point~ and 2 numbers).  A ~Square~
contains different data (a ~Point~ and 1 number).  What the Liskov
Substition Principle states is that if I have a method in the base
class that returns a ~Rect~ and override it with a method in the child
class that returns a ~Square~, then ~Square~ must be covariant with
~Rect~. It is covariant if, given that I have a function that converts
the contained data from ~Square~ data to ~Rect~ data, using it
I can construct a ~Rect~ from a ~Square~.

Of course we can do that.  The positions are the same, the length is
the same, and even though I don't have a height in ~Square~, I can
construct one from the length.  Using that, I can construct a ~Rect~
from a ~Square~.

Can you imagine a situation where the types are *not* covariant?
An example might be to have a ~Rect~ that has a colour, but a
~Square~ that does not have a colour.  There is no way to convert the
~Square~ to a ~Rect~ and so ~Square~ and ~Rect~ are not covariant.

By looking at this you can understand why return values from inherited
functions must be covariant.  If I have code that deals with ~Rect~
values and I give it a ~Square~ value, then the methods on ~Square~ must
return values that can be converted to the values that a ~Rect~ would
return.

In our immutable ~Square~ implementation, we return a ~Square~ from
~translate~ instead of a ~Rect~.  What the Liskov Substitution
Principle says is that as long as ~Square~ can be trivially converted
to ~Rect~ we are OK.  It's important to note that "trivially
converted" here means that the system takes care of it for you.  You
wouldn't actually write any code to convert it yourself.

**** Contravariance

As you might expect, "contravariance" is the opposite of covariance.
Imagine again that we have an array of numbers and we want an array of
letters.  However, instead of a function that converts numbers to
letters, we have a function that converts letters to numbers.  If we
can construct our array of letters, then we have a contravariant
relationship.

There is no nice way to say this: contravariance is weird.  Normally
we don't deal with contravariant relationships, so it's hard to
imagine how that would work.  Let's look at the statement from
the Liskov Substitution Problem: the arguments of the inherited
functions must be contravariant.

What this means that if I have a function in ~Rect~ and override it in
~Square~, there must be a function that converts the arguments from
the ~Rect~ version into the arguments in the ~Square~ version.  Like
the example of the numbers and letters, it's hard to imagine a
situation where this would work.  Of course it works if the arguments
are the *same*.  I'll try to explain how it might work if the
arguments are different.

Imagine that we had a method on a base class, called ~Base~.  The
arguments for this method are integer numbers.  We have a derived
class called ~Child~.  The arguments for the method on the child class
are floating point numbers.  Imagine that we can automatically convert
integers to floating point numbers.

In this case, the arguments of the methods in ~Child~ and ~Base~ are
contravariant.  I can convert integers to floats (~Base~ to ~Child~)
and therefore if I have code that expects a ~Base~ object, I can send
it a ~Child~ object and it will still work -- the system will
automatically convert the integers I use to the floating point numbers
that ~Child~ wants.

In practice, you will usually not write methods whose arguments differ
between base and child classes.  However, it can often occur if you
have optional values.  In that case the base class can have an
optional value, while the child class can either omit it or make it
required.  We can always convert from base class argument to child
class argument lists.


*** TODO Explain this
  It's important to understand that the closures from ~Rect~ are
  *different* than the closures from ~Square~.  The closures in ~Rect~
  will use the parameters from the call to ~Rect~, while the closures in
  ~Square~ will use the parameters from the call to ~Square~.  Since we
  are using immutable values, this is not a problem, because the values
  will all be equal.  However, this is going to cause us problems if
  we mutate any of those parameters.

** Thanks

Thanks to everyone for reading early versions of this post and
providing feedback.

Special thanks to Michael Cavanagh for suggesting the use of the
spread operator for inheritance (among other things).

Portions of this work were paid for by
[[https://www.palatinategroup.com/][Palatinate Group]].  I very much
appreciate their support.  As of this writing (March 24, 2018), they
are hiring for several positions, so feel free to contact them if you
are looking for work.

Although I was financially supported by Palatinate Group in this
effort, the views and opinions expressed in this repository are those
of the author and do not necessarily relect the views of Palatinate
Group or any affiliated entity.
